{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109a3ed7",
   "metadata": {},
   "source": [
    "# Embedding Model Comparison\n",
    "\n",
    "Objective:\n",
    "Select an embedding model that maximizes Recall@10 for SHL assessment retrieval\n",
    "while remaining production-safe and cost-effective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e817b58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json, faiss, numpy as np, pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from intent_intelligence.intent_resolver import resolve_intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bf657",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "catalog = json.load(open(\"../artifacts/shl_individual_assessments.json\"))\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "queries = train_df[\"Query\"].unique()\n",
    "truth = train_df.groupby(\"Query\")[\"Assessment_url\"].apply(list).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4781d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def recall_at_k(pred, rel, k=10):\n",
    "    return len(set(pred[:k]) & set(rel)) / max(1, len(rel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22062863",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_name):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    vecs = model.encode([c[\"semantic_profile_text\"] for c in catalog])\n",
    "    faiss.normalize_L2(vecs)\n",
    "\n",
    "    index = faiss.IndexFlatIP(vecs.shape[1])\n",
    "    index.add(vecs)\n",
    "\n",
    "    scores = []\n",
    "    for q in queries:\n",
    "        qv = model.encode([q])\n",
    "        faiss.normalize_L2(qv)\n",
    "        _, idx = index.search(qv, 10)\n",
    "        pred = [catalog[i][\"url\"] for i in idx[0]]\n",
    "        scores.append(recall_at_k(pred, truth[q]))\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4050d53a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"MiniLM-L6\": evaluate_model(\"all-MiniLM-L6-v2\"),\n",
    "    \"MPNet\": evaluate_model(\"all-mpnet-base-v2\")\n",
    "}\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"model\": k, \"Recall@10\": v} for k, v in results.items()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836bba6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "MPNet outperforms MiniLM on Recall@10.\n",
    "\n",
    "Given higher semantic fidelity and acceptable latency,\n",
    "MPNet is selected as the production embedding model.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
